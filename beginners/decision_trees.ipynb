{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1852e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [True,  \"HOT\",  \"HIGH\",   \"NO\"],\n",
    "    [True,  \"HOT\",  \"HIGH\",   \"NO\"],\n",
    "    [False, \"HOT\",  \"HIGH\",   \"YES\"],\n",
    "    [False, \"COOL\", \"NORMAL\", \"YES\"],\n",
    "    [False, \"COOL\", \"NORMAL\", \"YES\"],\n",
    "    [True,  \"COOL\", \"HIGH\",   \"NO\"],\n",
    "    [True,  \"HOT\",  \"HIGH\",   \"NO\"],\n",
    "    [True,  \"HOT\",  \"NORMAL\", \"YES\"],\n",
    "    [False, \"COOL\", \"NORMAL\", \"YES\"],\n",
    "    [False, \"COOL\", \"HIGH\", \"YES\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "553cbb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"a1\", \"a2\", \"a3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "acbb03e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c423a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    # print(labels)\n",
    "    total = len(labels)\n",
    "    # print(\"Total labels:\", total)\n",
    "    counts = Counter(labels)\n",
    "    # print(\"Label counts:\", counts)\n",
    "    ent = 0\n",
    "    for count in counts.values():\n",
    "        p = count / total\n",
    "        ent -= p*math.log2(p)\n",
    "    return ent\n",
    "# labels = [row[-1] for row in data]\n",
    "# ent = entropy(labels)\n",
    "# print(\"Entropy of the labels:\", ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b9ac9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(data,feature_index,target_attr):\n",
    "    labels = [row[target_attr] for row in data]\n",
    "    base_entropy = entropy(labels)\n",
    "    print(\"Base entropy:\", base_entropy)\n",
    "    #split by feature value\n",
    "    values = set(row[feature_index] for row in data)\n",
    "    print(\"vlaues:\",values)\n",
    "    weighted_entropy = 0\n",
    "    for val in values:\n",
    "        subset = [row for row in data if row[feature_index]== val]\n",
    "        subset_labels = [row[target_attr] for row in subset]\n",
    "        weighted_entropy +=(len(subset) /len(data)) * entropy(subset_labels)\n",
    "        print(f\"subset : {subset} subset_labels : {subset_labels} weighted_entropy: {weighted_entropy}\")\n",
    "        \n",
    "    return base_entropy - weighted_entropy\n",
    "\n",
    "# information_gain(data,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d602ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_class(data , target_attr):\n",
    "    values = [row[target_attr]for row in data]\n",
    "    print(\"Values:\", values)\n",
    "    return Counter(values).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cec25fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(data,features , target_attr):\n",
    "    labels = [row[target_attr] for row in data]\n",
    "    if labels.count(labels[0]) == len(labels):\n",
    "        return labels[0]\n",
    "    if not features:\n",
    "        return majority_class(data,target_attr)\n",
    "    \n",
    "    gains = [(attr , information_gain(data,attr , target_attr)) for attr in features]\n",
    "    best_attr = max(gains,key=lambda x:x[1])[0]\n",
    "    \n",
    "    tree = {best_attr:{}}\n",
    "    unique_vals = set(row[best_attr] for row in data)\n",
    "    \n",
    "    \n",
    "    for val in unique_vals:\n",
    "        subset = [row for row in data if row[best_attr] == val]\n",
    "        new_features = [f for f in features if f!=best_attr]\n",
    "        subtree = build_tree(subset,new_features,target_attr)\n",
    "        tree[best_attr][val] = subtree\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a912364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree , sample):\n",
    "    if not isinstance(tree , dict):\n",
    "        return tree\n",
    "\n",
    "    attr = next(iter(tree))\n",
    "    \n",
    "    if isinstance(sample , list):\n",
    "        value = sample[attr]\n",
    "    else:\n",
    "        value = sample.get(attr)\n",
    "\n",
    "    if value not in tree[attr]:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    return predict(tree[attr][value],sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e39b9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base entropy: 0.9709505944546686\n",
      "vlaues: {False, True}\n",
      "subset : [[False, 'HOT', 'HIGH', 'YES'], [False, 'COOL', 'NORMAL', 'YES'], [False, 'COOL', 'NORMAL', 'YES'], [False, 'COOL', 'NORMAL', 'YES'], [False, 'COOL', 'HIGH', 'YES']] subset_labels : ['YES', 'YES', 'YES', 'YES', 'YES'] weighted_entropy: 0.0\n",
      "subset : [[True, 'HOT', 'HIGH', 'NO'], [True, 'HOT', 'HIGH', 'NO'], [True, 'COOL', 'HIGH', 'NO'], [True, 'HOT', 'HIGH', 'NO'], [True, 'HOT', 'NORMAL', 'YES']] subset_labels : ['NO', 'NO', 'NO', 'NO', 'YES'] weighted_entropy: 0.36096404744368116\n",
      "Base entropy: 0.9709505944546686\n",
      "vlaues: {'HOT', 'COOL'}\n",
      "subset : [[True, 'HOT', 'HIGH', 'NO'], [True, 'HOT', 'HIGH', 'NO'], [False, 'HOT', 'HIGH', 'YES'], [True, 'HOT', 'HIGH', 'NO'], [True, 'HOT', 'NORMAL', 'YES']] subset_labels : ['NO', 'NO', 'YES', 'NO', 'YES'] weighted_entropy: 0.4854752972273343\n",
      "subset : [[False, 'COOL', 'NORMAL', 'YES'], [False, 'COOL', 'NORMAL', 'YES'], [True, 'COOL', 'HIGH', 'NO'], [False, 'COOL', 'NORMAL', 'YES'], [False, 'COOL', 'HIGH', 'YES']] subset_labels : ['YES', 'YES', 'NO', 'YES', 'YES'] weighted_entropy: 0.8464393446710154\n",
      "Base entropy: 0.9709505944546686\n",
      "vlaues: {'NORMAL', 'HIGH'}\n",
      "subset : [[False, 'COOL', 'NORMAL', 'YES'], [False, 'COOL', 'NORMAL', 'YES'], [True, 'HOT', 'NORMAL', 'YES'], [False, 'COOL', 'NORMAL', 'YES']] subset_labels : ['YES', 'YES', 'YES', 'YES'] weighted_entropy: 0.0\n",
      "subset : [[True, 'HOT', 'HIGH', 'NO'], [True, 'HOT', 'HIGH', 'NO'], [False, 'HOT', 'HIGH', 'YES'], [True, 'COOL', 'HIGH', 'NO'], [True, 'HOT', 'HIGH', 'NO'], [False, 'COOL', 'HIGH', 'YES']] subset_labels : ['NO', 'NO', 'YES', 'NO', 'NO', 'YES'] weighted_entropy: 0.5509775004326937\n",
      "Base entropy: 0.7219280948873623\n",
      "vlaues: {'HOT', 'COOL'}\n",
      "subset : [[True, 'HOT', 'HIGH', 'NO'], [True, 'HOT', 'HIGH', 'NO'], [True, 'HOT', 'HIGH', 'NO'], [True, 'HOT', 'NORMAL', 'YES']] subset_labels : ['NO', 'NO', 'NO', 'YES'] weighted_entropy: 0.6490224995673063\n",
      "subset : [[True, 'COOL', 'HIGH', 'NO']] subset_labels : ['NO'] weighted_entropy: 0.6490224995673063\n",
      "Base entropy: 0.7219280948873623\n",
      "vlaues: {'NORMAL', 'HIGH'}\n",
      "subset : [[True, 'HOT', 'NORMAL', 'YES']] subset_labels : ['YES'] weighted_entropy: 0.0\n",
      "subset : [[True, 'HOT', 'HIGH', 'NO'], [True, 'HOT', 'HIGH', 'NO'], [True, 'COOL', 'HIGH', 'NO'], [True, 'HOT', 'HIGH', 'NO']] subset_labels : ['NO', 'NO', 'NO', 'NO'] weighted_entropy: 0.0\n",
      "Decision Tree:\n",
      "{0: {False: 'YES', True: {2: {'NORMAL': 'YES', 'HIGH': 'NO'}}}}\n",
      "Prediction for [True, 'COOL', 'HIGH'] : NO\n"
     ]
    }
   ],
   "source": [
    "features = [0,1,2]\n",
    "target = -1\n",
    "tree = build_tree(data,features,target)\n",
    "print(\"Decision Tree:\")\n",
    "print(tree)\n",
    "\n",
    "test_sample = [True ,\"COOL\", \"HIGH\"]\n",
    "\n",
    "print(\"Prediction for\", test_sample, \":\", predict(tree, test_sample))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a5b6c758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing individual samples:\n",
      "Sample 1: [True, 'HOT', 'HIGH'] -> Prediction: NO\n",
      "Sample 2: [False, 'COOL', 'NORMAL'] -> Prediction: YES\n",
      "Sample 3: [True, 'COOL', 'NORMAL'] -> Prediction: YES\n",
      "Sample 4: [False, 'HOT', 'NORMAL'] -> Prediction: YES\n",
      "\n",
      "Test Accuracy: 100.0% (4/4)\n"
     ]
    }
   ],
   "source": [
    "test_samples = [\n",
    "    [True, \"HOT\", \"HIGH\"],      \n",
    "    [False, \"COOL\", \"NORMAL\"], \n",
    "    [True, \"COOL\", \"NORMAL\"],   \n",
    "    [False, \"HOT\", \"NORMAL\"],   \n",
    "]\n",
    "\n",
    "print(\"Testing individual samples:\")\n",
    "correct_predictions = 0\n",
    "total_samples = len(test_samples)\n",
    "\n",
    "for i, sample in enumerate(test_samples):\n",
    "    prediction = predict(tree, sample)\n",
    "    print(f\"Sample {i+1}: {sample} -> Prediction: {prediction}\")\n",
    "    \n",
    "    expected = [\"NO\", \"YES\", \"YES\", \"YES\"] \n",
    "    if prediction == expected[i]:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy_percentage = (correct_predictions / total_samples) * 100\n",
    "print(f\"\\nTest Accuracy: {accuracy_percentage:.1f}% ({correct_predictions}/{total_samples})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb137d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
